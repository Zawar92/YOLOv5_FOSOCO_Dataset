{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0de0a3-f055-4174-913d-37fccd15275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbe09f-df8c-485a-8316-d11d7cbe9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Step 1: Read image and text file\n",
    "image = cv2.imread('./ROI_test/1.png')  # Replace 'your_image.jpg' with the actual image file path\n",
    "with open('./ROI_test/1.txt', 'r') as file:  # Replace 'your_text_file.txt' with the actual text file path\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Step 2: Parse the text file\n",
    "objects = []\n",
    "for line in lines:\n",
    "    data = line.strip().split(' ')\n",
    "    obj_class = data[0]\n",
    "    x, y, w, h = map(float, data[1:])\n",
    "    objects.append({'class': obj_class, 'x': x, 'y': y, 'w': w, 'h': h})\n",
    "\n",
    "# Step 3: Calculate distances and sort objects\n",
    "reference_point = np.array([image.shape[1] // 2, image.shape[0] // 2])  # Use the center of the image as the reference point\n",
    "\n",
    "for obj in objects:\n",
    "    bbox_center = np.array([obj['x'] * image.shape[1] + obj['w'] * image.shape[1] / 2,\n",
    "                            obj['y'] * image.shape[0] + obj['h'] * image.shape[0] / 2])\n",
    "    obj['distance'] = np.linalg.norm(bbox_center - reference_point)\n",
    "\n",
    "objects.sort(key=lambda x: x['distance'])\n",
    "\n",
    "# Step 4 and 5: Keep objects in ROI and remove others\n",
    "roi_width = 1  # Adjust the width of the ROI based on your requirements\n",
    "roi_objects = [obj for obj in objects if obj['x'] + obj['w'] < roi_width]\n",
    "\n",
    "# Step 6: Draw bounding boxes on the image using provided method\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "for obj in roi_objects:\n",
    "    x_center_px = obj['x'] * image.shape[1]\n",
    "    y_center_px = obj['y'] * image.shape[0]\n",
    "    width_px = obj['w'] * image.shape[1]\n",
    "    height_px = obj['h'] * image.shape[0]\n",
    "\n",
    "    # Create a rectangle patch\n",
    "    rect = patches.Rectangle(\n",
    "        (x_center_px - width_px / 2, y_center_px - height_px / 2),\n",
    "        width_px, height_px,\n",
    "        linewidth=2, edgecolor='r', facecolor='none'\n",
    "    )\n",
    "\n",
    "    # Add the rectangle patch to the axis\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# Display the resulting image with rectangles\n",
    "plt.title('Bounding Boxes')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37308bd1-ebf4-4514-a102-22d061d9668a",
   "metadata": {},
   "source": [
    "# Closest Boxes to camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea4c72-4c54-4173-835d-4ba23ef221d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Hypothetical camera parameters (replace with actual values)\n",
    "focal_length = 1000.0  # in pixels\n",
    "sensor_width = 35.0  # in millimeters\n",
    "\n",
    "# Step 1: Read image and text file\n",
    "image = cv2.imread('./ROI_test/2.jpg')  # Replace 'your_image.jpg' with the actual image file path\n",
    "with open('./ROI_test/2.txt', 'r') as file:  # Replace 'your_text_file.txt' with the actual text file path\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Step 2: Parse the text file\n",
    "objects = []\n",
    "for line in lines:\n",
    "    data = line.strip().split(' ')\n",
    "    obj_class = data[0]\n",
    "    x, y, w, h = map(float, data[1:])\n",
    "    objects.append({'class': obj_class, 'x': x, 'y': y, 'w': w, 'h': h})\n",
    "\n",
    "# Step 3: Calculate distances and sort objects\n",
    "reference_point = np.array([image.shape[1] // 2, image.shape[0] // 2])  # Use the center of the image as the reference point\n",
    "\n",
    "for obj in objects:\n",
    "    bbox_center = np.array([obj['x'] * image.shape[1] + obj['w'] * image.shape[1] / 2,\n",
    "                            obj['y'] * image.shape[0] + obj['h'] * image.shape[0] / 2])\n",
    "    obj['distance'] = np.linalg.norm(bbox_center - reference_point)\n",
    "\n",
    "objects.sort(key=lambda x: x['distance'])\n",
    "\n",
    "# Step 4: Draw bounding boxes on the image using provided method\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Define a threshold area for the bounding box size\n",
    "threshold_area = 5000.0  # Adjust the threshold area based on your requirements\n",
    "\n",
    "for obj in objects:\n",
    "    x_center_px = obj['x'] * image.shape[1]\n",
    "    y_center_px = obj['y'] * image.shape[0]\n",
    "    width_px = obj['w'] * image.shape[1]\n",
    "    height_px = obj['h'] * image.shape[0]\n",
    "\n",
    "    # Calculate the area of the bounding box\n",
    "    bbox_area = width_px * height_px\n",
    "\n",
    "    # Check if the bounding box size is above the threshold\n",
    "    if bbox_area > threshold_area:\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle(\n",
    "            (x_center_px - width_px / 2, y_center_px - height_px / 2),\n",
    "            width_px, height_px,\n",
    "            linewidth=2, edgecolor='r', facecolor='none'\n",
    "        )\n",
    "\n",
    "        # Add the rectangle patch to the axis\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Calculate and print the estimated distance (replace with actual camera parameters)\n",
    "        estimated_distance = (10.0 * focal_length) / width_px  # Assuming real object width is 10.0 units\n",
    "        print(f\"Object at ({x_center_px}, {y_center_px}) is estimated to be at a distance of {estimated_distance} units.\")\n",
    "\n",
    "# Display the resulting image with rectangles\n",
    "plt.title('Bounding Boxes with Estimated Distances (Size Condition)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2a2c3-4ea6-478a-b0a1-3b5e90f68a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01073b05-2e0f-4d12-8b12-7fe2481b9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Hypothetical camera parameters (replace with actual values)\n",
    "focal_length = 1000.0  # in pixels\n",
    "sensor_width = 35.0  # in millimeters\n",
    "\n",
    "# Step 1: Read image and text file\n",
    "image = cv2.imread('./ROI_test/gfr_00544_jpg.jpg')  # Replace 'your_image.jpg' with the actual image file path\n",
    "with open('./ROI_test/gfr_00544_jpg.txt', 'r') as file:  # Replace 'your_text_file.txt' with the actual text file path\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Step 2: Parse the text file\n",
    "objects = []\n",
    "for line in lines:\n",
    "    data = line.strip().split(' ')\n",
    "    obj_class = data[0]\n",
    "    x, y, w, h = map(float, data[1:])\n",
    "    objects.append({'class': obj_class, 'x': x, 'y': y, 'w': w, 'h': h})\n",
    "\n",
    "# Step 3: Calculate distances and sort objects\n",
    "reference_point = np.array([image.shape[1] // 2, image.shape[0] // 2])  # Use the center of the image as the reference point\n",
    "\n",
    "for obj in objects:\n",
    "    bbox_center = np.array([obj['x'] * image.shape[1] + obj['w'] * image.shape[1] / 2,\n",
    "                            obj['y'] * image.shape[0] + obj['h'] * image.shape[0] / 2])\n",
    "    obj['distance'] = np.linalg.norm(bbox_center - reference_point)\n",
    "\n",
    "objects.sort(key=lambda x: x['distance'])\n",
    "\n",
    "# Step 4: Draw bounding boxes on the image using provided method\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Define a threshold area for the bounding box size\n",
    "threshold_area = 5000.0  # Adjust the threshold area based on your requirements\n",
    "\n",
    "covered_objects = []  # Store covered objects for cropping\n",
    "for obj in objects:\n",
    "    x_center_px = obj['x'] * image.shape[1]\n",
    "    y_center_px = obj['y'] * image.shape[0]\n",
    "    width_px = obj['w'] * image.shape[1]\n",
    "    height_px = obj['h'] * image.shape[0]\n",
    "\n",
    "    # Calculate the area of the bounding box\n",
    "    bbox_area = width_px * height_px\n",
    "\n",
    "    # Check if the bounding box size is above the threshold\n",
    "    if bbox_area > threshold_area:\n",
    "        # print(bbox_area, threshold_area)\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle(\n",
    "            (x_center_px - width_px / 2, y_center_px - height_px / 2),\n",
    "            width_px, height_px,\n",
    "            linewidth=2, edgecolor='r', facecolor='none'\n",
    "        )\n",
    "\n",
    "        # Add the rectangle patch to the axis\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Store covered objects for cropping\n",
    "        covered_objects.append(obj)\n",
    "\n",
    "# Display the resulting image with rectangles\n",
    "plt.title('Bounding Boxes with Estimated Distances (Size Condition)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Crop the image based on the covered bounding boxes\n",
    "min_x, min_y, max_x, max_y = np.inf, np.inf, -np.inf, -np.inf\n",
    "\n",
    "for obj in covered_objects:\n",
    "    x_center_px = obj['x'] * image.shape[1]\n",
    "    y_center_px = obj['y'] * image.shape[0]\n",
    "    width_px = obj['w'] * image.shape[1]\n",
    "    height_px = obj['h'] * image.shape[0]\n",
    "\n",
    "    min_x = min(min_x, x_center_px - width_px / 2)\n",
    "    min_y = min(min_y, y_center_px - height_px / 2)\n",
    "    max_x = max(max_x, x_center_px + width_px / 2)\n",
    "    max_y = max(max_y, y_center_px + height_px / 2)\n",
    "\n",
    "# Ensure the coordinates are within the image boundaries\n",
    "min_x, min_y, max_x, max_y = max(0, min_x), max(0, min_y), min(image.shape[1], max_x), min(image.shape[0], max_y)\n",
    "\n",
    "# Crop the image\n",
    "cropped_image = image[int(min_y):int(max_y), int(min_x):int(max_x)]\n",
    "\n",
    "# Resize the image to 640 by 640 while maintaining the aspect ratio\n",
    "aspect_ratio = cropped_image.shape[1] / cropped_image.shape[0]\n",
    "new_height = int(640)\n",
    "new_width = int(640 * aspect_ratio)\n",
    "resized_image = cv2.resize(cropped_image, (new_width, new_height))\n",
    "\n",
    "# Display the cropped and resized image\n",
    "plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Cropped and Resized Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Create new bounding boxes on the cropped and resized image\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "for obj in covered_objects:\n",
    "    # Adjust bounding box coordinates to fit the new image dimensions\n",
    "    x_center_px = ((obj['x'] * image.shape[1]) - min_x) / (max_x - min_x) * resized_image.shape[1]\n",
    "    y_center_px = ((obj['y'] * image.shape[0]) - min_y) / (max_y - min_y) * resized_image.shape[0]\n",
    "    width_px = obj['w'] * resized_image.shape[1]\n",
    "    height_px = obj['h'] * resized_image.shape[0]\n",
    "\n",
    "    # Create a rectangle patch\n",
    "    rect = patches.Rectangle(\n",
    "        (x_center_px - width_px / 2, y_center_px - height_px / 2),\n",
    "        width_px, height_px,\n",
    "        linewidth=2, edgecolor='r', facecolor='none'\n",
    "    )\n",
    "\n",
    "    # Add the rectangle patch to the axis\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# Display the resulting image with new rectangles\n",
    "plt.title('New Bounding Boxes on Cropped and Resized Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a2e99-5177-45da-9d05-cbafc6b4822f",
   "metadata": {},
   "source": [
    "# Testing Analysis for closer cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0adf9d-700b-433c-ace4-37f1cef433e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "model = torch.hub.load('../yolov5', 'custom', path='../train_trainvalid_dist_augment_voc/fine-tuning-background-augment/weights/best.pt', source='local') \n",
    "img = 'ROI_test/gfr_00544_jpg.jpg'\n",
    "\n",
    "\n",
    "results = model(img)\n",
    "\n",
    "image = cv2.imread('ROI_test/gfr_00544_jpg.jpg')\n",
    "df = results.pandas().xywh[0]\n",
    "# print(df)\n",
    "\n",
    "objects = []\n",
    "for index, row in df.iterrows():\n",
    "    objects.append({'class': row['class'], 'x': row['xcenter'], 'y': row['ycenter'], 'w': row['width'], 'h': row['height'], 'conf':  row['confidence'], 'index': index})\n",
    "\n",
    "reference_point = np.array([image.shape[1] // 2, image.shape[0] // 2])  # Use the center of the image as the reference point\n",
    "\n",
    "for obj in objects:\n",
    "    bbox_center = np.array([obj['x'] * image.shape[1] + obj['w'] * image.shape[1] / 2,\n",
    "                            obj['y'] * image.shape[0] + obj['h'] * image.shape[0] / 2])\n",
    "    obj['distance'] = np.linalg.norm(bbox_center - reference_point)\n",
    "\n",
    "objects.sort(key=lambda x: x['distance'])\n",
    "\n",
    "threshold_area = 4000.0 \n",
    "\n",
    "covered_objects = []\n",
    "df['area'] = df['width'] * df['height']\n",
    "\n",
    "close_df = df[df['area'] > threshold_area]\n",
    "close_df['depth_id'] = 0\n",
    "close_df['depth_name'] = 'close_from_cam'\n",
    "\n",
    "far_df = df[df['area'] <= threshold_area]\n",
    "far_df['depth_id'] = 1\n",
    "far_df['depth_name'] = 'far_from_cam'\n",
    "\n",
    "final_df = pd.concat([close_df, far_df], axis=0)\n",
    "final_df['image_name'] = os.path.basename(img)\n",
    "final_df.to_csv('filtered.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503cb28c-075d-48f8-a0f7-8add6fd40d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcdef4-fa0f-4c33-a1ce-5d97d86e9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "\n",
    "# Read the image using cv2.imread\n",
    "image_path = 'ROI_test/gfr_00544_jpg.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert BGR to RGB (cv2 uses BGR order)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_rgb)\n",
    "\n",
    "filtered_rows = pd.read_csv('filtered.csv', sep='\\t', index_col=None)\n",
    "\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    rect = patches.Rectangle((row['xcenter'] - row['width'] / 2, row['ycenter'] - row['height'] / 2),\n",
    "                             row['width'], row['height'], linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(row['xcenter'], row['ycenter'], f\"Object {index}\", color='r', fontsize=8, verticalalignment='top')\n",
    "\n",
    "# Highlight bounding boxes above the threshold\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    rect = patches.Rectangle((row['xcenter'] - row['width'] / 2, row['ycenter'] - row['height'] / 2),\n",
    "                             row['width'], row['height'], linewidth=2, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# Set aspect ratio and axis limits\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_xlim(0, image.shape[1])\n",
    "ax.set_ylim(image.shape[0], 0)  # Inverted y-axis to fix upside-down image\n",
    "\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Bounding Boxes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6102729-f7f5-4c58-ac2d-d53564860355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed26a7-fa42-4d4c-9dfc-477d1d2b7726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
