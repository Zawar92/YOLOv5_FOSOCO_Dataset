{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420e9836-f2e2-4f5a-a9c3-8d57a1c2604a",
   "metadata": {},
   "source": [
    "# Fine Tune using hyp.VOC.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca759c-4350-499b-b826-8335e9baf9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ccb530-7c7e-4b33-9845-4ccf4f34b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a8f0e-8076-4ecb-bb21-29a82f6f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"yolov5_train/fine_tune_hyp_voc_with_background\"\n",
    "BASE_MODEL = \"yolov5m6.pt\"\n",
    "TRAIN_BATCH = 16\n",
    "TRAIN_EPOCHS = 100\n",
    "VAL_BATCH = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010cc2b4-13fe-4fd3-b544-267624219b89",
   "metadata": {},
   "source": [
    ">lr0: 0.00334\n",
    "\n",
    ">lrf: 0.15135\n",
    "\n",
    ">momentum: 0.74832\n",
    "\n",
    ">weight_decay: 0.00025\n",
    "\n",
    ">warmup_epochs: 3.3835\n",
    "\n",
    ">warmup_momentum: 0.59462\n",
    "\n",
    ">warmup_bias_lr: 0.18657\n",
    "\n",
    ">box: 0.02\n",
    "\n",
    ">cls: 0.21638\n",
    "\n",
    ">cls_pw: 0.5\n",
    "\n",
    ">obj: 0.51728\n",
    "\n",
    ">obj_pw: 0.67198\n",
    "\n",
    ">iou_t: 0.2\n",
    "\n",
    ">anchor_t: 3.3744\n",
    "\n",
    ">fl_gamma: 0.0\n",
    "\n",
    ">hsv_h: 0.01041\n",
    "\n",
    ">hsv_s: 0.54703\n",
    "\n",
    ">hsv_v: 0.27739\n",
    "\n",
    ">degrees: 0.0\n",
    "\n",
    ">translate: 0.04591\n",
    "\n",
    ">scale: 0.75544\n",
    "\n",
    ">shear: 0.0\n",
    "\n",
    ">perspective: 0.0\n",
    "\n",
    ">flipud: 0.0\n",
    "\n",
    ">fliplr: 0.5\n",
    "\n",
    ">mosaic: 0.85834\n",
    "\n",
    ">mixup: 0.04266\n",
    "\n",
    ">copy_paste: 0.0\n",
    "\n",
    ">anchors: 3.412"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fabb2-0da4-4747-a902-291af5264d55",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad577b84-ffae-43ea-b8c8-8e30a1ea1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINE TUNING: Orignal train batch as base weight file.\n",
    "WEIGHTS_BEST = \"yolov5_train/feature_extraction/weights/best.pt\"\n",
    "!python3.10 yolov5/train.py --hyp 'yolov5/data/hyps/hyp.VOC.yaml' --batch $TRAIN_BATCH --epochs $TRAIN_EPOCHS --data 'data.yaml' --weights $WEIGHTS_BEST --project $PROJECT_NAME --name 'fine-tuning' --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719a929-86a0-4df1-a839-7a6a51967353",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('yolov5_train/fine_tune_hyp_voc/fine-tuning/results.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bc820-0741-4621-8c32-6c57d59b185f",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da64def-297d-4f3e-bd00-41e30b10113c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_BEST = \"yolov5_train/fine_tune_hyp_voc_with_background/fine-tuning/weights/best.pt\"\n",
    "PROJECT_NAME = \"yolov5_train/fine_tune_hyp_voc_with_background\"\n",
    "!python3.10 yolov5/val.py --weights $WEIGHTS_BEST --batch 64 --data 'data.yaml' --task test --project $PROJECT_NAME --name 'validation_on_test_data' --augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac22ee-46ce-44f2-a741-4c4c0cebda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('yolov5_train/fine_tune_hyp_voc_with_background/validation_on_test_data/confusion_matrix.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47743a2f-731b-46b2-ad50-819e0f0e5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('yolov5_train/fine_tune_hyp_voc_with_background/validation_on_test_data/PR_curve.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d5ffc-88b4-44f4-a878-576fa21c5071",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0d723-48f5-4bd9-85a1-af58f2ae9ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_BEST = \"yolov5_train/fine_tune_hyp_voc_with_background/fine-tuning/weights/best.pt\"\n",
    "PROJECT_NAME = \"yolov5_train/fine_tune_hyp_voc_with_background\"\n",
    "!python3.10 yolov5/detect.py --weights $WEIGHTS_BEST  --conf 0.6 --source 'yolov5/data/test/images' --project $PROJECT_NAME --name 'detect_test' --augment --line=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61b1f5-f74a-415b-a640-1cd45601f1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e0e5b-8892-4870-af65-de2ef7d3bca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
